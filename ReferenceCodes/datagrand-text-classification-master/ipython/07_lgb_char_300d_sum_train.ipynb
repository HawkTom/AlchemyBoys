{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "train_data_file = \"../processed_data/train-data-300d-sum.txt\"\n",
    "test_data_file = \"../processed_data/test-data-300d-sum.txt\"\n",
    "df_train = pd.read_csv(train_data_file)\n",
    "df_test = pd.read_csv(test_data_file)\n",
    "\n",
    "X_train = df_train.drop(['class'], axis=1)\n",
    "y_train = df_train['class'] - 1\n",
    "X_test = df_test\n",
    "num_feats = X_train.shape[1]\n",
    "num_classes = max(y_train) + 1\n",
    "\n",
    "del df_train, df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the LightGBM model and make submission\n",
    "lgb_train = lgb.Dataset(X_train.values, y_train.values)\n",
    "\n",
    "df_params = pd.read_csv(\"lgb-char-300d-tuning-results.csv\").sort_values(by='f1_val', ascending=False)\n",
    "for i in range(1):\n",
    "    params = {\n",
    "        'boosting_type': df_params['type'].values[i],\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': num_classes,\n",
    "        'metric': 'multi_logloss',\n",
    "\n",
    "        'learning_rate': df_params['lr'].values[i],\n",
    "\n",
    "        'num_leaves': df_params['n_leaf'].values[i],\n",
    "        'max_depth': df_params['n_depth'].values[i],\n",
    "        'min_data_in_leaf': df_params['min_data'].values[i],\n",
    "\n",
    "        'feature_fraction': df_params['feat_frac'].values[i],\n",
    "        'bagging_fraction': df_params['bagging_frac'].values[i],\n",
    "        'bagging_freq': df_params['bagging_freq'].values[i],\n",
    "\n",
    "        'lambda_l1': df_params['l1'].values[i],\n",
    "        'lambda_l2': df_params['l2'].values[i],\n",
    "        'min_gain_to_split': df_params['min_gain'].values[i],\n",
    "        'min_sum_hessian_in_leaf': df_params['hessian'].values[i],\n",
    "\n",
    "        'num_threads': 16,\n",
    "        'verbose': 0,\n",
    "        'is_training_metric': 'True'\n",
    "    }\n",
    "\n",
    "    print(\"Hyper-parameters:\")\n",
    "    print(params)\n",
    "\n",
    "    num_epochs = df_params['best_iter'].values[i]\n",
    "    print(\"Round number: %d\" % num_epochs)\n",
    "\n",
    "    print(\"Start training...\")\n",
    "    evals_result = {}\n",
    "    gbm = lgb.train(params=params,\n",
    "                    train_set=lgb_train,\n",
    "                    num_boost_round=num_epochs,\n",
    "                    valid_sets=lgb_train,\n",
    "                    valid_names=['train'],\n",
    "                    evals_result=evals_result,\n",
    "                    verbose_eval=100)\n",
    "    print(\"Training finished! ^_^\")\n",
    "\n",
    "    best_iter = gbm.best_iteration\n",
    "    loss_train = evals_result['train']['multi_logloss'][best_iter-1]\n",
    "\n",
    "    probs_train = gbm.predict(X_train, num_iteration=best_iter)\n",
    "    preds_train = np.argmax(probs_train, axis=1)\n",
    "    acc_train = accuracy_score(y_train, preds_train)\n",
    "    f1_train = f1_score(y_train, preds_train, average='weighted')\n",
    "\n",
    "    print(\"Best round: %d\" % best_iter)\n",
    "    print(\"Training Loss: %.5f\" % loss_train)\n",
    "    print(\"Training Accuracy: %.2f\" % (acc_train * 100))\n",
    "    print(\"Training F1 Score: %.5f\" % f1_train)\n",
    "\n",
    "    feature_importance = pd.DataFrame({'name': gbm.feature_name(), 'importance': gbm.feature_importance()})\n",
    "    feature_importance.sort_values(by='importance', ascending=False, inplace=True)\n",
    "    feature_importance.to_csv(\"feature-importance-char-300d.csv\", index=False)\n",
    "\n",
    "    # Make submission\n",
    "    probs_test = gbm.predict(X_test)\n",
    "    preds_test = np.argmax(probs_test, axis=1) + 1\n",
    "    df_test = pd.read_csv(\"../raw_data/test_demo.csv\")\n",
    "    submission = pd.DataFrame()\n",
    "    submission['id'] = df_test['id']\n",
    "    submission['class'] = preds_test\n",
    "    submission.to_csv(\"2018-07-16_lgb-char-300d-sum-submission.txt\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
