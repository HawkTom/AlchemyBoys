{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "from sklearn.svm import LinearSVC\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "The number of samples is: 4999\n",
      "The number of classes is: 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Load data\n",
    "\n",
    "print(\"Loading data...\")\n",
    "data_file = \"../raw_data/train_demo.csv\"\n",
    "df_data = pd.read_csv(data_file)\n",
    "\n",
    "X_text = df_data['word_seg']  # words of samples (documents)\n",
    "y = df_data['class']  # labels (1 ~ 19)\n",
    "num_classes = max(y)\n",
    "print(\"The number of samples is: %d\" % len(X_text))\n",
    "print(\"The number of classes is: %d\" % num_classes)\n",
    "\n",
    "del df_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Load character/word embedding\n",
    "\n",
    "word_embed_file = \"../processed_data/train-data-300d-mean.txt\"\n",
    "word_embed = pd.read_csv(word_embed_file).drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer's hyper-parameters:\n",
      "{'max_df': 0.9,\n",
      " 'max_features': 100,\n",
      " 'min_df': 5,\n",
      " 'ngram_range': (1, 2),\n",
      " 'sublinear_tf': True}\n",
      "Extract features...\n",
      "Done in 16.600 seconds\n",
      "Extract finished! ( ^ _ ^ ) V\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Extract TF-IDF features\n",
    "\n",
    "vect_params = {\n",
    "    'ngram_range': (1, 2),\n",
    "    'min_df': 5,\n",
    "    'max_df': 0.9,\n",
    "    'max_features': 100,\n",
    "    'sublinear_tf': True\n",
    "}\n",
    "vectorizer = TfidfVectorizer(**vect_params)\n",
    "print(\"Vectorizer's hyper-parameters:\")\n",
    "pprint(vect_params)\n",
    "\n",
    "print(\"Extract features...\")\n",
    "t0_extract = time()\n",
    "X = vectorizer.fit_transform(X_text)\n",
    "print(\"Done in %.3f seconds\" % (time() - t0_extract))\n",
    "print(\"Extract finished! ( ^ _ ^ ) V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Concatenate TF-IDF features and embedding features\n",
    "\n",
    "X = hstack([X, csr_matrix(word_embed)], format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0932443 ,  0.        ,  0.22077235, ..., -0.04485132,\n",
       "         0.14054012,  0.04720277],\n",
       "       [ 0.12778936,  0.11224537,  0.1177972 , ..., -0.10544113,\n",
       "         0.02626771, -0.01324177],\n",
       "       [ 0.        ,  0.10095127,  0.03691131, ..., -0.12735154,\n",
       "        -0.07328191,  0.11236589],\n",
       "       ...,\n",
       "       [ 0.08160263,  0.1013473 ,  0.17281348, ..., -0.09613179,\n",
       "        -0.00730957,  0.09377087],\n",
       "       [ 0.07481859,  0.07473134,  0.10008863, ...,  0.06953936,\n",
       "         0.00994381, -0.06601639],\n",
       "       [ 0.18337967,  0.14777703,  0.23950951, ..., -0.0775608 ,\n",
       "        -0.05436005,  0.11374065]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into training and validation set...\n",
      "Start training...\n",
      "Done in 22.287 seconds\n",
      "Training finish! ( ^ _ ^ ) V \n",
      "Train Accuracy: 99.97, Validate Accuracy: 69.10\n",
      "Train F1 Score: 0.99975, Validate F1 Score: 0.68977\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Train the SVM model\n",
    "\n",
    "print(\"Split data into training and validation set...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Start training...\")\n",
    "clf = LinearSVC()\n",
    "t0_train = time()\n",
    "clf.fit(X_train, y_train - 1)  # labels must be in (0, 18)\n",
    "print(\"Done in %.3f seconds\" % (time() - t0_train))\n",
    "print(\"Training finish! ( ^ _ ^ ) V \")\n",
    "\n",
    "pred_train = clf.predict(X_train) + 1\n",
    "pred_val = clf.predict(X_val) + 1\n",
    "acc_train = accuracy_score(y_train, pred_train)\n",
    "acc_val = accuracy_score(y_val, pred_val)\n",
    "f1_train = f1_score(y_train, pred_train, average='weighted')\n",
    "f1_val = f1_score(y_val, pred_val, average='weighted')\n",
    "print(\"Train Accuracy: %.2f, Validate Accuracy: %.2f\" % (acc_train * 100, acc_val * 100))\n",
    "print(\"Train F1 Score: %.5f, Validate F1 Score: %.5f\" % (f1_train, f1_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
